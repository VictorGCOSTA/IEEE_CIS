{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quandidade de elementos 0 e 1 Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n",
      "(284315, 31)\n",
      "(492, 31)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(984, 31)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv('./creditcard.csv')\n",
    "#Verificando a quantidade de fraudes\n",
    "print(f\"Quandidade de elementos 0 e 1 {ds.Class.value_counts()}\")\n",
    "ds.value_counts()\n",
    "v1 = ds[ds['Class'] == 1 ]\n",
    "v0 = ds[ds['Class'] == 0 ]\n",
    "print(v0.shape)\n",
    "v0 = v0.sample(492, replace=True) \n",
    "print(v0.shape)\n",
    "ds = pd.concat([v1, v0], axis=0)\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_step_func(x):\n",
    "    return np.where(x > 0 , 1, 0)\n",
    "\n",
    "class Perceptron:\n",
    "\n",
    "    def __init__(self, learning_rate=0.01, n_iters=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.activation_func = unit_step_func\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # init parameters\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        y_ = np.where(y > 0 , 1, 0)\n",
    "\n",
    "        #print(y)\n",
    "        #print(y_)\n",
    "        #print(np.array_equal(y, y_) )\n",
    "        # learn weights\n",
    "        for _ in range(self.n_iters):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
    "                #print(linear_output)\n",
    "                y_predicted = self.activation_func(linear_output)\n",
    "                #print(y_predicted)\n",
    "                #print(self.weights, self.bias)\n",
    "                #print(f\"y_pred = {y_predicted}, y = {y_[idx]}\")\n",
    "                if y_predicted != y_[idx]:  # Only update when prediction is incorrect\n",
    "                    #print(\"Entrou aqui 1\")\n",
    "                    update =  self.lr * (y_[idx] - y_predicted) * x_i\n",
    "                    self.weights += update\n",
    "                    update_bias = self.lr * (y_[idx] - y_predicted)\n",
    "                    self.bias += update_bias\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        #print(linear_output)\n",
    "        y_predicted = self.activation_func(linear_output)\n",
    "        return y_predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1]\n",
      "[1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1]\n",
      "Acur치cia:  1.0\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "X, y = datasets.make_blobs(\n",
    "        n_samples=150, n_features=2, centers=2, cluster_std=1.05, random_state=2\n",
    "    )\n",
    "X_train, X_teste, y_train, y_teste = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "p = Perceptron(learning_rate=0.1, n_iters=1000)\n",
    "p.fit(X_train, y_train)\n",
    "predictions = p.predict(X_teste)\n",
    "print(y_teste)\n",
    "print(predictions)\n",
    "print(\"Acur치cia: \", metrics.accuracy_score(y_teste, predictions))\n",
    "print(\"Classification report: \\n\", metrics.classification_report(y_teste, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 1. 0.]\n",
      "[1 1 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1\n",
      " 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0\n",
      " 1 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 1 0 0 0\n",
      " 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1\n",
      " 1 1 0 0 0 1 0 1 1 0 1 0]\n",
      "Acur치cia:  0.817258883248731\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.66      0.78        98\n",
      "         1.0       0.74      0.97      0.84        99\n",
      "\n",
      "    accuracy                           0.82       197\n",
      "   macro avg       0.85      0.82      0.81       197\n",
      "weighted avg       0.85      0.82      0.81       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in ds.columns:\n",
    "    ds[c] = (ds [c] - min(ds[c]))/(max(ds[c]) -min(ds[c]))\n",
    "#print(ds.head())\n",
    "X= np.array(ds.drop(['Class'], axis=1))\n",
    "y= np.array(ds['Class'])\n",
    "X_train, X_teste, y_train, y_teste = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#print(X_train.shape)\n",
    "p = Perceptron(learning_rate=0.1, n_iters=1000)\n",
    "p.fit(X_train, y_train)\n",
    "predictions = p.predict(X_teste)\n",
    "print(y_teste)\n",
    "print(predictions)\n",
    "print(\"Acur치cia: \", metrics.accuracy_score(y_teste, predictions))\n",
    "print(\"Classification report: \\n\", metrics.classification_report(y_teste, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 10ms/step - loss: 0.6589 - accuracy: 0.5946 - val_loss: 0.6379 - val_accuracy: 0.6709\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.7782 - val_loss: 0.5626 - val_accuracy: 0.7848\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.8277 - val_loss: 0.4937 - val_accuracy: 0.8354\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.8573 - val_loss: 0.4179 - val_accuracy: 0.8734\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8602 - val_loss: 0.3756 - val_accuracy: 0.8734\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8898 - val_loss: 0.3435 - val_accuracy: 0.8734\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3265 - accuracy: 0.8927 - val_loss: 0.3249 - val_accuracy: 0.8734\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3019 - accuracy: 0.8955 - val_loss: 0.3410 - val_accuracy: 0.8734\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2791 - accuracy: 0.9011 - val_loss: 0.2820 - val_accuracy: 0.8861\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.2605 - accuracy: 0.9096 - val_loss: 0.2802 - val_accuracy: 0.8861\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.2432 - accuracy: 0.9110 - val_loss: 0.2512 - val_accuracy: 0.9114\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2550 - accuracy: 0.9223 - val_loss: 0.2432 - val_accuracy: 0.8987\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2249 - accuracy: 0.9223 - val_loss: 0.2647 - val_accuracy: 0.8861\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2216 - accuracy: 0.9195 - val_loss: 0.2506 - val_accuracy: 0.8861\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2169 - accuracy: 0.9167 - val_loss: 0.2270 - val_accuracy: 0.8987\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2117 - accuracy: 0.9209 - val_loss: 0.2327 - val_accuracy: 0.8987\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2074 - accuracy: 0.9223 - val_loss: 0.2357 - val_accuracy: 0.8987\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1971 - accuracy: 0.9280 - val_loss: 0.2230 - val_accuracy: 0.8987\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1932 - accuracy: 0.9364 - val_loss: 0.2128 - val_accuracy: 0.8987\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1999 - accuracy: 0.9237 - val_loss: 0.2181 - val_accuracy: 0.8987\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1886 - accuracy: 0.9350 - val_loss: 0.2701 - val_accuracy: 0.8861\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1922 - accuracy: 0.9308 - val_loss: 0.2417 - val_accuracy: 0.9114\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1843 - accuracy: 0.9364 - val_loss: 0.2680 - val_accuracy: 0.8987\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1876 - accuracy: 0.9308 - val_loss: 0.2247 - val_accuracy: 0.8987\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1807 - accuracy: 0.9336 - val_loss: 0.2106 - val_accuracy: 0.8987\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1797 - accuracy: 0.9322 - val_loss: 0.2316 - val_accuracy: 0.8987\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.9308 - val_loss: 0.2165 - val_accuracy: 0.8987\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1801 - accuracy: 0.9322 - val_loss: 0.2346 - val_accuracy: 0.8987\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1770 - accuracy: 0.9364 - val_loss: 0.2182 - val_accuracy: 0.8987\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1707 - accuracy: 0.9350 - val_loss: 0.2034 - val_accuracy: 0.9114\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1805 - accuracy: 0.9350 - val_loss: 0.2141 - val_accuracy: 0.8987\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1833 - accuracy: 0.9308 - val_loss: 0.2839 - val_accuracy: 0.9114\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1860 - accuracy: 0.9322 - val_loss: 0.2890 - val_accuracy: 0.9114\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1761 - accuracy: 0.9364 - val_loss: 0.2467 - val_accuracy: 0.8987\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1833 - accuracy: 0.9364 - val_loss: 0.2166 - val_accuracy: 0.8987\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1712 - accuracy: 0.9350 - val_loss: 0.2572 - val_accuracy: 0.8987\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1656 - accuracy: 0.9322 - val_loss: 0.2124 - val_accuracy: 0.8987\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1756 - accuracy: 0.9393 - val_loss: 0.2066 - val_accuracy: 0.8987\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1665 - accuracy: 0.9294 - val_loss: 0.2092 - val_accuracy: 0.8987\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1676 - accuracy: 0.9336 - val_loss: 0.2567 - val_accuracy: 0.8987\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1712 - accuracy: 0.9350 - val_loss: 0.2651 - val_accuracy: 0.8987\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1674 - accuracy: 0.9379 - val_loss: 0.2330 - val_accuracy: 0.8987\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1911 - accuracy: 0.9350 - val_loss: 0.2507 - val_accuracy: 0.8987\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.9322 - val_loss: 0.2057 - val_accuracy: 0.8987\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1743 - accuracy: 0.9435 - val_loss: 0.2086 - val_accuracy: 0.8987\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9322 - val_loss: 0.2239 - val_accuracy: 0.8987\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1643 - accuracy: 0.9379 - val_loss: 0.2544 - val_accuracy: 0.8987\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1597 - accuracy: 0.9350 - val_loss: 0.2373 - val_accuracy: 0.8987\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1649 - accuracy: 0.9393 - val_loss: 0.2962 - val_accuracy: 0.8987\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1740 - accuracy: 0.9393 - val_loss: 0.2085 - val_accuracy: 0.8987\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.2112 - accuracy: 0.9223 - val_loss: 0.2095 - val_accuracy: 0.8987\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1861 - accuracy: 0.9364 - val_loss: 0.2124 - val_accuracy: 0.8987\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1609 - accuracy: 0.9364 - val_loss: 0.2108 - val_accuracy: 0.8987\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1591 - accuracy: 0.9364 - val_loss: 0.2174 - val_accuracy: 0.8987\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1713 - accuracy: 0.9449 - val_loss: 0.2183 - val_accuracy: 0.8987\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1643 - accuracy: 0.9379 - val_loss: 0.2363 - val_accuracy: 0.8987\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1715 - accuracy: 0.9350 - val_loss: 0.2488 - val_accuracy: 0.8987\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1601 - accuracy: 0.9449 - val_loss: 0.2547 - val_accuracy: 0.8987\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1653 - accuracy: 0.9421 - val_loss: 0.2454 - val_accuracy: 0.8987\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1617 - accuracy: 0.9364 - val_loss: 0.2140 - val_accuracy: 0.8987\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1612 - accuracy: 0.9379 - val_loss: 0.2617 - val_accuracy: 0.8987\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1667 - accuracy: 0.9393 - val_loss: 0.2124 - val_accuracy: 0.8987\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1955 - accuracy: 0.9294 - val_loss: 0.2108 - val_accuracy: 0.8861\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1603 - accuracy: 0.9421 - val_loss: 0.2141 - val_accuracy: 0.8987\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1593 - accuracy: 0.9379 - val_loss: 0.2339 - val_accuracy: 0.8987\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1562 - accuracy: 0.9421 - val_loss: 0.2287 - val_accuracy: 0.8987\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1549 - accuracy: 0.9379 - val_loss: 0.2619 - val_accuracy: 0.8987\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1565 - accuracy: 0.9364 - val_loss: 0.2162 - val_accuracy: 0.8987\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1489 - accuracy: 0.9477 - val_loss: 0.3558 - val_accuracy: 0.9114\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1597 - accuracy: 0.9421 - val_loss: 0.2367 - val_accuracy: 0.8987\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1561 - accuracy: 0.9435 - val_loss: 0.2294 - val_accuracy: 0.8987\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1676 - accuracy: 0.9364 - val_loss: 0.2254 - val_accuracy: 0.8987\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1560 - accuracy: 0.9407 - val_loss: 0.2137 - val_accuracy: 0.8987\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1724 - accuracy: 0.9379 - val_loss: 0.2172 - val_accuracy: 0.8987\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1834 - accuracy: 0.9435 - val_loss: 0.2167 - val_accuracy: 0.9114\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1679 - accuracy: 0.9421 - val_loss: 0.2501 - val_accuracy: 0.8987\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1631 - accuracy: 0.9350 - val_loss: 0.2800 - val_accuracy: 0.8987\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1569 - accuracy: 0.9463 - val_loss: 0.2478 - val_accuracy: 0.8987\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1521 - accuracy: 0.9520 - val_loss: 0.2643 - val_accuracy: 0.8987\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1524 - accuracy: 0.9492 - val_loss: 0.2396 - val_accuracy: 0.8987\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1518 - accuracy: 0.9421 - val_loss: 0.2208 - val_accuracy: 0.8987\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1517 - accuracy: 0.9407 - val_loss: 0.2465 - val_accuracy: 0.8987\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1575 - accuracy: 0.9407 - val_loss: 0.2591 - val_accuracy: 0.8987\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1510 - accuracy: 0.9407 - val_loss: 0.2281 - val_accuracy: 0.8987\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1619 - accuracy: 0.9407 - val_loss: 0.2658 - val_accuracy: 0.8987\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1866 - accuracy: 0.9364 - val_loss: 0.2631 - val_accuracy: 0.8987\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1540 - accuracy: 0.9407 - val_loss: 0.2289 - val_accuracy: 0.8987\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1523 - accuracy: 0.9477 - val_loss: 0.2346 - val_accuracy: 0.8987\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1608 - accuracy: 0.9449 - val_loss: 0.2262 - val_accuracy: 0.8987\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1649 - accuracy: 0.9379 - val_loss: 0.2453 - val_accuracy: 0.8987\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1532 - accuracy: 0.9421 - val_loss: 0.2747 - val_accuracy: 0.8987\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9435 - val_loss: 0.2203 - val_accuracy: 0.8987\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1505 - accuracy: 0.9477 - val_loss: 0.2287 - val_accuracy: 0.8987\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1633 - accuracy: 0.9506 - val_loss: 0.2483 - val_accuracy: 0.8987\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1481 - accuracy: 0.9421 - val_loss: 0.2574 - val_accuracy: 0.8987\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.9407 - val_loss: 0.2554 - val_accuracy: 0.8987\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1550 - accuracy: 0.9506 - val_loss: 0.2632 - val_accuracy: 0.8987\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9463 - val_loss: 0.3175 - val_accuracy: 0.8987\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1716 - accuracy: 0.9407 - val_loss: 0.3098 - val_accuracy: 0.8987\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1542 - accuracy: 0.9449 - val_loss: 0.2634 - val_accuracy: 0.8987\n",
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics\n",
    "\n",
    "#Modelo de MLP usando tensorflow\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "#Camada de sa칤da para classifica칞칚o bin치ria\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#Compilando modelo\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Treinando\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "\n",
    "\n",
    "# Previs칫es\n",
    "predictions = model.predict(X_teste)\n",
    "predictions_classes = (predictions > 0.5).astype(int).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur치cia:  0.9390862944162437\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.98      0.94        98\n",
      "         1.0       0.98      0.90      0.94        99\n",
      "\n",
      "    accuracy                           0.94       197\n",
      "   macro avg       0.94      0.94      0.94       197\n",
      "weighted avg       0.94      0.94      0.94       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Acur치cia: \", metrics.accuracy_score(y_teste, predictions_classes))\n",
    "print(\"Classification report: \\n\", metrics.classification_report(y_teste, predictions_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
