{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quandidade de elementos 0 e 1 Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n",
      "(284315, 31)\n",
      "(492, 31)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(984, 31)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv('./creditcard.csv')\n",
    "#Verificando a quantidade de fraudes\n",
    "print(f\"Quandidade de elementos 0 e 1 {ds.Class.value_counts()}\")\n",
    "ds.value_counts()\n",
    "v1 = ds[ds['Class'] == 1 ]\n",
    "v0 = ds[ds['Class'] == 0 ]\n",
    "print(v0.shape)\n",
    "v0 = v0.sample(492, replace=True) \n",
    "print(v0.shape)\n",
    "ds = pd.concat([v1, v0], axis=0)\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_step_func(x):\n",
    "    return np.where(x > 0 , 1, 0)\n",
    "\n",
    "class Perceptron:\n",
    "\n",
    "    def __init__(self, learning_rate=0.01, n_iters=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.activation_func = unit_step_func\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # init parameters\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        y_ = np.where(y > 0 , 1, 0)\n",
    "\n",
    "        #print(y)\n",
    "        #print(y_)\n",
    "        #print(np.array_equal(y, y_) )\n",
    "        for _ in range(self.n_iters):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
    "                #print(linear_output)\n",
    "                y_predicted = self.activation_func(linear_output)\n",
    "                #print(y_predicted)\n",
    "                #print(self.weights, self.bias)\n",
    "                #print(f\"y_pred = {y_predicted}, y = {y_[idx]}\")\n",
    "                if y_predicted != y_[idx]: \n",
    "                    #print(\"Entrou aqui 1\")\n",
    "                    update =  self.lr * (y_[idx] - y_predicted) * x_i\n",
    "                    self.weights += update\n",
    "                    update_bias = self.lr * (y_[idx] - y_predicted)\n",
    "                    self.bias += update_bias\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        #print(linear_output)\n",
    "        y_predicted = self.activation_func(linear_output)\n",
    "        return y_predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1]\n",
      "[1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1]\n",
      "Acur치cia:  1.0\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "X, y = datasets.make_blobs(\n",
    "        n_samples=150, n_features=2, centers=2, cluster_std=1.05, random_state=2\n",
    "    )\n",
    "X_train, X_teste, y_train, y_teste = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "p = Perceptron(learning_rate=0.1, n_iters=1000)\n",
    "p.fit(X_train, y_train)\n",
    "predictions = p.predict(X_teste)\n",
    "print(y_teste)\n",
    "print(predictions)\n",
    "print(\"Acur치cia: \", metrics.accuracy_score(y_teste, predictions))\n",
    "print(\"Classification report: \\n\", metrics.classification_report(y_teste, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 1. 0.]\n",
      "[1 1 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1\n",
      " 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0\n",
      " 1 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 1 0 0 0\n",
      " 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1\n",
      " 1 1 0 0 0 1 0 1 1 0 1 0]\n",
      "Acur치cia:  0.817258883248731\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.66      0.78        98\n",
      "         1.0       0.74      0.97      0.84        99\n",
      "\n",
      "    accuracy                           0.82       197\n",
      "   macro avg       0.85      0.82      0.81       197\n",
      "weighted avg       0.85      0.82      0.81       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in ds.columns:\n",
    "    ds[c] = (ds [c] - min(ds[c]))/(max(ds[c]) -min(ds[c]))\n",
    "#print(ds.head())\n",
    "X= np.array(ds.drop(['Class'], axis=1))\n",
    "y= np.array(ds['Class']).T\n",
    "X_train, X_teste, y_train, y_teste = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#print(X_train.shape)\n",
    "p = Perceptron(learning_rate=0.1, n_iters=1000)\n",
    "p.fit(X_train, y_train)\n",
    "predictions = p.predict(X_teste)\n",
    "print(y_teste)\n",
    "print(predictions)\n",
    "print(\"Acur치cia: \", metrics.accuracy_score(y_teste, predictions))\n",
    "print(\"Classification report: \\n\", metrics.classification_report(y_teste, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 64ms/step - loss: 0.9482 - accuracy: 0.3241 - val_loss: 0.7754 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7666 - accuracy: 0.3056 - val_loss: 0.6712 - val_accuracy: 0.9167\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6312 - accuracy: 0.8056 - val_loss: 0.5934 - val_accuracy: 0.7500\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5338 - accuracy: 0.8148 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4663 - accuracy: 0.8056 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4218 - accuracy: 0.8056 - val_loss: 0.4692 - val_accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3894 - accuracy: 0.8056 - val_loss: 0.4446 - val_accuracy: 0.7500\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3597 - accuracy: 0.8148 - val_loss: 0.4211 - val_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3353 - accuracy: 0.8426 - val_loss: 0.3965 - val_accuracy: 0.9167\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3122 - accuracy: 0.8611 - val_loss: 0.3708 - val_accuracy: 0.9167\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2910 - accuracy: 0.8611 - val_loss: 0.3454 - val_accuracy: 0.9167\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2716 - accuracy: 0.8796 - val_loss: 0.3204 - val_accuracy: 0.9167\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2519 - accuracy: 0.8981 - val_loss: 0.2970 - val_accuracy: 0.9167\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2355 - accuracy: 0.9167 - val_loss: 0.2765 - val_accuracy: 0.9167\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2202 - accuracy: 0.9259 - val_loss: 0.2566 - val_accuracy: 0.9167\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2056 - accuracy: 0.9352 - val_loss: 0.2378 - val_accuracy: 0.9167\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1919 - accuracy: 0.9444 - val_loss: 0.2200 - val_accuracy: 0.9167\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1793 - accuracy: 0.9444 - val_loss: 0.2031 - val_accuracy: 0.9167\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1673 - accuracy: 0.9444 - val_loss: 0.1877 - val_accuracy: 0.9167\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1569 - accuracy: 0.9444 - val_loss: 0.1734 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1475 - accuracy: 0.9444 - val_loss: 0.1606 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1385 - accuracy: 0.9722 - val_loss: 0.1489 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1310 - accuracy: 0.9722 - val_loss: 0.1383 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1232 - accuracy: 0.9722 - val_loss: 0.1285 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1153 - accuracy: 0.9722 - val_loss: 0.1207 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1092 - accuracy: 0.9815 - val_loss: 0.1146 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1046 - accuracy: 0.9815 - val_loss: 0.1085 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0985 - accuracy: 0.9815 - val_loss: 0.1014 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0928 - accuracy: 0.9815 - val_loss: 0.0937 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0868 - accuracy: 0.9815 - val_loss: 0.0875 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0825 - accuracy: 0.9815 - val_loss: 0.0816 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0780 - accuracy: 0.9815 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0723 - accuracy: 0.9815 - val_loss: 0.0697 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0679 - accuracy: 0.9815 - val_loss: 0.0652 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0637 - accuracy: 0.9907 - val_loss: 0.0608 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0598 - accuracy: 0.9907 - val_loss: 0.0563 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0564 - accuracy: 0.9907 - val_loss: 0.0518 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0520 - accuracy: 0.9907 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0485 - accuracy: 0.9907 - val_loss: 0.0445 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0456 - accuracy: 0.9907 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 73ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics\n",
    "\n",
    "#Modelo de MLP usando tensorflow\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "#Camada de sa칤da para classifica칞칚o bin치ria\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#Compilando modelo\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Treinando\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "\n",
    "\n",
    "# Previs칫es\n",
    "predictions = model.predict(X_teste)\n",
    "predictions_classes = (predictions > 0.5).astype(int).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur치cia:  1.0\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Acur치cia: \", metrics.accuracy_score(y_teste, predictions_classes))\n",
    "print(\"Classification report: \\n\", metrics.classification_report(y_teste, predictions_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
